{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigm = lambda x: 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    \n",
    "    def __init__(self,NC,NN,ActFun,rate=0.1): # Jugar con la tasa de mutacion\n",
    "        \n",
    "        self.NC = NC\n",
    "        self.NN = NN\n",
    "        self.ActFunc = ActFun\n",
    "        self.rate = rate\n",
    "        \n",
    "        self.W = np.random.uniform( -10.,10.,(self.NC,self.NN) )\n",
    "        self.b = np.random.uniform( -10.,10.,(1,self.NN) )\n",
    "        \n",
    "    def Activation(self,x):\n",
    "        z = np.dot(x,self.W) + self.b\n",
    "        return self.ActFunc( z )[0]\n",
    "    \n",
    "    def Mutate(self):\n",
    "    \n",
    "        #self.W += np.random.normal( loc=0., scale=self.rate, size=(self.NC,self.NN))\n",
    "        #self.b += np.random.normal( loc=0., scale=self.rate, size=(1,self.NN))\n",
    "        \n",
    "        self.W += np.random.uniform( -self.rate, self.rate, size=(self.NC,self.NN))\n",
    "        self.b += np.random.uniform( -self.rate, self.rate, size=(1,self.NN))\n",
    "def GetBrain():\n",
    "    l0 = Layer(1,5,sigm)\n",
    "    l1 = Layer(5,1,sigm)\n",
    "    #l2 = Layer(2,1,sigm)\n",
    "    Brain = [l0,l1]\n",
    "    return Brain  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot:\n",
    "    \n",
    "    def __init__(self, dt, Layers, Id=0):\n",
    "        \n",
    "        self.Id = Id\n",
    "        self.dt = dt\n",
    "        \n",
    "        \n",
    "        self.r = np.random.uniform([0.,0.])\n",
    "        theta = 0.\n",
    "        self.v = np.array([1.*np.cos(theta),1.*np.sin(theta)])\n",
    "\n",
    "        \n",
    "        # Capacidad o aptitud del individuo\n",
    "        self.Fitness = np.inf\n",
    "        self.Steps = 0\n",
    "\n",
    "        # Brain\n",
    "        self.Layers = Layers\n",
    "        \n",
    "    def GetR(self):\n",
    "        return self.r\n",
    "    \n",
    "    def Evolution(self):\n",
    "        self.r += self.v*self.dt # Euler integration (Metodos 2)\n",
    "\n",
    "        # Cada generación regreamos el robot al origin\n",
    "        # Y volvemos a estimar su fitness\n",
    "    def Reset(self):\n",
    "        self.Steps = 0.\n",
    "        self.r = np.array([0.,0.])\n",
    "        self.Fitness = np.inf    \n",
    "        \n",
    "    # Aca debes definir que es mejorar en tu proceso evolutivo\n",
    "    def SetFitness(self):\n",
    "        self.Fitness = 1/self.Steps # Esto no hace nada por ahora\n",
    "        \n",
    "        \n",
    "       # Brain stuff\n",
    "    def BrainActivation(self,x,threshold=0.7): \n",
    "        for i in range(len(self.Layers)):         \n",
    "            if i == 0:\n",
    "                output = self.Layers[i].Activation(x)\n",
    "            else:\n",
    "                output = self.Layers[i].Activation(output)\n",
    "        \n",
    "        self.Activation = np.round(output,4)\n",
    "    \n",
    "        # Cambiamos el vector velocidad\n",
    "        if self.Activation[0] > threshold:\n",
    "            self.v = -self.v\n",
    "            self.Steps-=0.7\n",
    "    \n",
    "        return self.Activation\n",
    "    \n",
    "    # Aca mutamos (cambiar de parametros) para poder \"aprender\"\n",
    "    def Mutate(self):\n",
    "        for i in range(len(self.Layers)):\n",
    "            self.Layers[i].Mutate()\n",
    "    \n",
    "    # Devolvemos la red neuronal ya entrenada\n",
    "    def GetBrain(self):\n",
    "        return self.Layers\n",
    "def GetRobots(N):\n",
    "    \n",
    "    Robots = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        Brain = GetBrain()\n",
    "        r = Robot(dt,Brain,Id=i)\n",
    "        Robots.append(r)\n",
    "        \n",
    "    return Robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "t = np.arange(0.,5.,dt)\n",
    "Robots = GetRobots(100)\n",
    "\n",
    "def GetPlot():\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax1 = fig.add_subplot(1,2,2)\n",
    "    \n",
    "    ax.set_xlim(-1.,1.)\n",
    "    ax.set_ylim(-1.,1.)\n",
    " \n",
    "    return ax,ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeEvolution(Robots,e,Plot=True):\n",
    "    \n",
    "  \n",
    "    for it in range(t.shape[0]):\n",
    "        \n",
    "        if Plot:\n",
    "        \n",
    "            clear_output(wait=True)\n",
    "        \n",
    "            ax,ax1 = GetPlot()\n",
    "            ax1.set_ylim(0.,1.)\n",
    "        \n",
    "            ax.set_title('t = {:.3f}'.format(t[it]))\n",
    "        \n",
    "        Activation = np.zeros(len(Robots))\n",
    "        \n",
    "        for i,p in enumerate(Robots):\n",
    "            p.Evolution()\n",
    "         \n",
    "            # Activacion cerebral\n",
    "            Act = p.BrainActivation(p.GetR()[0])\n",
    "            Activation[i] = Act\n",
    "            # Region donde aumentamos los pasos para el fitness\n",
    "            \n",
    "            if -1. <= p.GetR()[0]  and 1. >= p.GetR()[0]:\n",
    "                p.Steps += 1\n",
    "                \n",
    "            if Plot and i < 5: # Solo pintamos los primeros 5, por tiempo de computo\n",
    "                ax.scatter(p.r[0],p.r[1],label='Id: {}, Steps: {:.0f}'.format(p.Id,p.Steps))\n",
    "                ax.quiver(p.r[0],p.r[1],p.v[0],p.v[1])\n",
    "                \n",
    "        # Pintamos la activaciones de los primeros 5\n",
    "        \n",
    "        if Plot:\n",
    "            ax1.plot(np.arange(0,len(Robots[:5]),1),Activation[:5],marker='o',color='b',label='Activation')\n",
    "            ax1.axhline(y=0.7,color='r')\n",
    "        \n",
    "        if Plot:\n",
    "        \n",
    "            ax.legend(loc=0)  \n",
    "            ax1.legend(loc=0)\n",
    "            plt.show()\n",
    "            time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la rutina de entrenamiento\n",
    "def Genetic(Robots, epochs = 200, Plot = True, Plottime=False):\n",
    "    \n",
    "    # Porcentaje de robots elegidos en cada epoch\n",
    "    N = int(0.3*len(Robots))\n",
    "    \n",
    "    FitVector = np.array([])\n",
    "    \n",
    "    \n",
    "    x = np.linspace(-1,1,20)\n",
    "    Act = np.zeros_like(x)\n",
    "    \n",
    "    for e in range(int(epochs)):\n",
    "        \n",
    "        # Reiniciamos y mutamos los pesos\n",
    "        \n",
    "        for p in Robots:\n",
    "            p.Reset() \n",
    "            p.Mutate()\n",
    "            \n",
    "        # Evolucionamos\n",
    "        TimeEvolution(Robots,e,Plottime) # Apagar dibujar la evolución para entrenar\n",
    "        \n",
    "        # Actualizamos fitness de cada robot\n",
    "        for i,p in enumerate(Robots):\n",
    "            p.SetFitness()\n",
    "        \n",
    "        # Aca va toda la rutina de ordenar los bots del más apto al menos apto\n",
    "        \n",
    "        \n",
    "        # Guardamos el mejor fitness y le mejor robot\n",
    "        best_fitness = 0.\n",
    "        best_bot = Robots[0] #Esto no es asi, deben ver como se elige al mejor\n",
    "        \n",
    "        FitVector = np.append(FitVector,best_fitness)\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            Act[i] = best_bot.BrainActivation(x[i])\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        print('Epoch:', e)\n",
    "                \n",
    "        # Last fitness\n",
    "        print('Last Fitness:', FitVector[-1])\n",
    "        \n",
    "        \n",
    "        if Plot:\n",
    "            \n",
    "            ax,ax1 = GetPlot()\n",
    "            ax.plot(x,Act,color='k')\n",
    "            ax.set_ylim(0.,1)\n",
    "            ax.axhline(y=0.75,ls='--',color='r',label='Threshold')\n",
    "            \n",
    "            ax1.set_title('Fitness')\n",
    "            ax1.plot(FitVector)\n",
    "        \n",
    "            ax.legend(loc=0)\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            time.sleep(0.01)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return best_bot, FitVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Robots = GetRobots(10)\n",
    "#Best, FitVector = Genetic(Robots,Plot=True,Plottime=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
